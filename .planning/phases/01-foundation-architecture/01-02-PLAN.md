---
phase: 01-foundation-architecture
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - app/models.py
autonomous: true

must_haves:
  truths:
    - "Database schema supports files, jobs, duplicates, and user decisions"
    - "Job status transitions follow PENDING -> RUNNING -> COMPLETED/FAILED"
    - "Files can be linked to duplicates with similarity scores"
    - "User decisions are recorded with timestamps"
  artifacts:
    - path: "app/models.py"
      provides: "SQLAlchemy models for File, Job, Duplicate, UserDecision"
      contains: "class File"
    - path: "app/models.py"
      provides: "Job status enum"
      contains: "class JobStatus"
  key_links:
    - from: "app/models.py"
      to: "app/__init__.py"
      via: "imports db from app"
      pattern: "from app import db"
---

<objective>
Create SQLAlchemy database models for files, jobs, duplicates, and user decisions using SQLAlchemy 2.x type-safe patterns.

Purpose: Provides the data layer that all processing and review features depend on. Addresses INFRA-03 (database stores file metadata, hashes, and user decisions).

Output: Complete database schema ready for job queue and file processing.
</objective>

<execution_context>
@/home/dab/.claude/get-shit-done/workflows/execute-plan.md
@/home/dab/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/phases/01-foundation-architecture/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create SQLAlchemy models with type-safe patterns</name>
  <files>
    app/models.py
  </files>
  <action>
Create app/models.py with SQLAlchemy 2.x type-safe models following RESEARCH.md patterns:

1. **Imports:**
   ```python
   from datetime import datetime, timezone
   from enum import Enum as PyEnum
   from typing import Optional, List
   from sqlalchemy import Integer, String, DateTime, Float, Text, ForeignKey, Index
   from sqlalchemy import Enum as SQLEnum, event, text
   from sqlalchemy.orm import Mapped, mapped_column, relationship
   from sqlalchemy.engine import Engine
   from app import db
   ```

2. **JobStatus Enum:**
   ```python
   class JobStatus(str, PyEnum):
       PENDING = "pending"
       RUNNING = "running"
       COMPLETED = "completed"
       FAILED = "failed"
   ```

3. **ConfidenceLevel Enum:**
   ```python
   class ConfidenceLevel(str, PyEnum):
       HIGH = "high"        # Multiple sources agree
       MEDIUM = "medium"    # Single reliable source
       LOW = "low"          # Filename only or conflicts
       NONE = "none"        # No timestamp found
   ```

4. **File Model:**
   - id: Mapped[int] (primary key, INTEGER for SQLite performance)
   - original_filename: Mapped[str] (String 255, not null)
   - original_path: Mapped[str] (String 500, not null) - path relative to upload folder
   - storage_path: Mapped[str] (String 500) - current location in storage
   - file_hash_sha256: Mapped[Optional[str]] (String 64, indexed) - for exact duplicate detection
   - file_hash_perceptual: Mapped[Optional[str]] (String 64) - for near-duplicate detection (Phase 6)
   - file_size_bytes: Mapped[Optional[int]] (Integer)
   - mime_type: Mapped[Optional[str]] (String 100)
   - detected_timestamp: Mapped[Optional[datetime]] (DateTime, timezone-aware)
   - timestamp_source: Mapped[Optional[str]] (String 50) - 'exif', 'filename', 'filesystem', 'user'
   - confidence: Mapped[ConfidenceLevel] (Enum, default LOW)
   - output_path: Mapped[Optional[str]] (String 500) - final output location
   - created_at: Mapped[datetime] (DateTime, default utcnow)
   - updated_at: Mapped[datetime] (DateTime, default utcnow, onupdate utcnow)
   - Relationships: jobs, duplicate_records

5. **Job Model:**
   - id: Mapped[int] (primary key)
   - job_type: Mapped[str] (String 50) - 'import', 'process', 'export'
   - status: Mapped[JobStatus] (Enum, default PENDING)
   - progress_current: Mapped[int] (default 0) - files processed
   - progress_total: Mapped[int] (default 0) - total files
   - created_at: Mapped[datetime]
   - started_at: Mapped[Optional[datetime]]
   - completed_at: Mapped[Optional[datetime]]
   - error_message: Mapped[Optional[str]] (Text) - full error for debugging
   - retry_count: Mapped[int] (default 0)
   - Relationships: files (many-to-many via job_files association)

6. **JobFile Association Table** (for many-to-many Job<->File):
   ```python
   job_files = db.Table('job_files',
       db.Column('job_id', Integer, ForeignKey('jobs.id'), primary_key=True),
       db.Column('file_id', Integer, ForeignKey('files.id'), primary_key=True)
   )
   ```

7. **Duplicate Model:**
   - id: Mapped[int] (primary key)
   - file_id: Mapped[int] (ForeignKey files.id)
   - duplicate_of_id: Mapped[int] (ForeignKey files.id)
   - match_type: Mapped[str] (String 20) - 'exact' or 'perceptual'
   - similarity_score: Mapped[float] (Float) - 1.0 for exact, 0.0-1.0 for perceptual
   - detected_at: Mapped[datetime]
   - Relationships: file, duplicate_of

8. **UserDecision Model:**
   - id: Mapped[int] (primary key)
   - file_id: Mapped[int] (ForeignKey files.id)
   - decision_type: Mapped[str] (String 50) - 'timestamp_override', 'keep_duplicate', 'discard_duplicate', 'tag_assignment'
   - decision_value: Mapped[str] (Text) - JSON or simple value depending on type
   - decided_at: Mapped[datetime]
   - Relationship: file

9. **SQLite Foreign Key Enforcement:**
   Add event listener to enable foreign keys:
   ```python
   @event.listens_for(Engine, "connect")
   def set_sqlite_pragma(dbapi_conn, connection_record):
       cursor = dbapi_conn.cursor()
       cursor.execute("PRAGMA foreign_keys=ON")
       cursor.close()
   ```

10. **Indexes:**
    - Index on files.file_hash_sha256 for duplicate lookup
    - Index on files.detected_timestamp for date-based queries
    - Index on jobs.status for queue queries
    - Composite index on duplicates(file_id, duplicate_of_id)
  </action>
  <verify>
    python -c "from app.models import File, Job, Duplicate, UserDecision, JobStatus, ConfidenceLevel; print('Models OK')"
  </verify>
  <done>
    - All four model classes defined with type hints
    - JobStatus and ConfidenceLevel enums work
    - Foreign key relationships properly defined
    - Indexes defined for performance-critical queries
  </done>
</task>

<task type="auto">
  <name>Task 2: Initialize database and verify schema</name>
  <files>
    app/__init__.py
  </files>
  <action>
Update app/__init__.py to:

1. Import models in create_app() to register them with SQLAlchemy:
   ```python
   with app.app_context():
       from app import models  # noqa: F401 - registers models
       db.create_all()
   ```

2. Add WAL mode setup for SQLite after db.init_app(app):
   ```python
   @app.before_request
   def setup_sqlite():
       if 'sqlite' in app.config.get('SQLALCHEMY_DATABASE_URI', ''):
           with db.engine.connect() as conn:
               conn.execute(text('PRAGMA journal_mode=WAL'))
               conn.execute(text('PRAGMA busy_timeout=5000'))
               conn.commit()
   ```

   Actually, better to do this once at startup, not per-request. Use:
   ```python
   with app.app_context():
       from app import models
       if 'sqlite' in app.config.get('SQLALCHEMY_DATABASE_URI', ''):
           with db.engine.connect() as conn:
               conn.execute(text('PRAGMA journal_mode=WAL'))
               conn.execute(text('PRAGMA busy_timeout=5000'))
               conn.commit()
       db.create_all()
   ```

3. Create a simple test script to verify schema creation:
   ```python
   # test_schema.py (temporary, can delete after verification)
   from app import create_app, db
   from app.models import File, Job, Duplicate, UserDecision, JobStatus

   app = create_app()
   with app.app_context():
       # Create a test job
       job = Job(job_type='import', status=JobStatus.PENDING, progress_total=10)
       db.session.add(job)
       db.session.commit()
       print(f"Created job with id={job.id}, status={job.status.value}")

       # Clean up
       db.session.delete(job)
       db.session.commit()
       print("Schema verification passed!")
   ```
  </action>
  <verify>
    python -c "
from app import create_app, db
from app.models import File, Job, JobStatus
app = create_app()
with app.app_context():
    job = Job(job_type='test', status=JobStatus.PENDING, progress_total=1)
    db.session.add(job)
    db.session.commit()
    print(f'Job created: id={job.id}')
    db.session.delete(job)
    db.session.commit()
    print('Schema OK')
"
  </verify>
  <done>
    - Database file created at instance/mediaparser.db
    - All tables created (files, jobs, job_files, duplicates, user_decisions)
    - WAL mode enabled for SQLite
    - Jobs can be created and persisted
  </done>
</task>

</tasks>

<verification>
1. Run `sqlite3 instance/mediaparser.db ".tables"` - should show: duplicates files job_files jobs user_decisions
2. Run `sqlite3 instance/mediaparser.db "PRAGMA journal_mode"` - should show: wal
3. Run `sqlite3 instance/mediaparser.db ".schema files"` - should show all columns
4. Python verification: create File, Job, link them, query back
</verification>

<success_criteria>
- Database schema matches requirements from RESEARCH.md
- All four main tables exist: files, jobs, duplicates, user_decisions
- Many-to-many relationship between jobs and files works
- SQLite WAL mode enabled for concurrent access
- Foreign key constraints enforced
- Type-safe models with Mapped[] annotations
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-architecture/01-02-SUMMARY.md`
</output>
