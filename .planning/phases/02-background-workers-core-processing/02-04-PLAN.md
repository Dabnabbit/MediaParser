---
phase: 02-background-workers-core-processing
plan: 04
type: execute
wave: 4
depends_on: ["02-03"]
files_modified:
  - tests/test_processing.py
  - tests/conftest.py
autonomous: true

must_haves:
  truths:
    - "Unit tests verify hashing functions work correctly"
    - "Unit tests verify confidence scoring algorithm"
    - "Integration test verifies end-to-end job processing"
    - "Tests run in isolation without affecting production data"
  artifacts:
    - path: "tests/test_processing.py"
      provides: "Phase 2 processing tests"
      min_lines: 100
    - path: "tests/conftest.py"
      provides: "Pytest fixtures for Phase 2"
      contains: ["sample_image", "sample_file"]
  key_links:
    - from: "tests/test_processing.py"
      to: "app/lib/hashing.py"
      via: "import"
      pattern: "from app\\.lib\\.hashing import"
    - from: "tests/test_processing.py"
      to: "app/lib/confidence.py"
      via: "import"
      pattern: "from app\\.lib\\.confidence import"
---

<objective>
Create comprehensive tests for Phase 2 processing functionality.

Purpose: Verify that hashing functions, confidence scoring, and the complete processing pipeline work correctly. Tests ensure the multi-threaded processing doesn't have race conditions and database updates are correct.

Output: tests/test_processing.py with unit and integration tests for Phase 2.
</objective>

<execution_context>
@/home/dab/.claude/get-shit-done/workflows/execute-plan.md
@/home/dab/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/phases/02-background-workers-core-processing/02-CONTEXT.md
@.planning/phases/02-background-workers-core-processing/02-RESEARCH.md
@.planning/phases/02-background-workers-core-processing/02-01-SUMMARY.md
@.planning/phases/02-background-workers-core-processing/02-02-SUMMARY.md
@.planning/phases/02-background-workers-core-processing/02-03-SUMMARY.md

Existing test patterns:
@tests/conftest.py (if exists)
@tests/test_integration.py (if exists)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add test fixtures for sample files</name>
  <files>tests/conftest.py</files>
  <action>
Update tests/conftest.py to add fixtures for Phase 2 testing:

1. Add fixture for temporary test files:
   ```python
   import tempfile
   from pathlib import Path

   @pytest.fixture
   def temp_dir():
       """Create a temporary directory for test files."""
       with tempfile.TemporaryDirectory() as tmpdir:
           yield Path(tmpdir)

   @pytest.fixture
   def sample_text_file(temp_dir):
       """Create a sample text file for hashing tests."""
       file_path = temp_dir / "test.txt"
       file_path.write_text("Hello, World!")
       return file_path

   @pytest.fixture
   def sample_image_file(temp_dir):
       """Create a minimal valid JPEG file for perceptual hashing tests."""
       # Minimal 1x1 JPEG (red pixel)
       # This is a valid JPEG that imagehash can process
       jpeg_bytes = bytes([
           0xFF, 0xD8, 0xFF, 0xE0, 0x00, 0x10, 0x4A, 0x46, 0x49, 0x46, 0x00, 0x01,
           0x01, 0x00, 0x00, 0x01, 0x00, 0x01, 0x00, 0x00, 0xFF, 0xDB, 0x00, 0x43,
           0x00, 0x08, 0x06, 0x06, 0x07, 0x06, 0x05, 0x08, 0x07, 0x07, 0x07, 0x09,
           0x09, 0x08, 0x0A, 0x0C, 0x14, 0x0D, 0x0C, 0x0B, 0x0B, 0x0C, 0x19, 0x12,
           0x13, 0x0F, 0x14, 0x1D, 0x1A, 0x1F, 0x1E, 0x1D, 0x1A, 0x1C, 0x1C, 0x20,
           0x24, 0x2E, 0x27, 0x20, 0x22, 0x2C, 0x23, 0x1C, 0x1C, 0x28, 0x37, 0x29,
           0x2C, 0x30, 0x31, 0x34, 0x34, 0x34, 0x1F, 0x27, 0x39, 0x3D, 0x38, 0x32,
           0x3C, 0x2E, 0x33, 0x34, 0x32, 0xFF, 0xC0, 0x00, 0x0B, 0x08, 0x00, 0x01,
           0x00, 0x01, 0x01, 0x01, 0x11, 0x00, 0xFF, 0xC4, 0x00, 0x1F, 0x00, 0x00,
           0x01, 0x05, 0x01, 0x01, 0x01, 0x01, 0x01, 0x01, 0x00, 0x00, 0x00, 0x00,
           0x00, 0x00, 0x00, 0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08,
           0x09, 0x0A, 0x0B, 0xFF, 0xC4, 0x00, 0xB5, 0x10, 0x00, 0x02, 0x01, 0x03,
           0x03, 0x02, 0x04, 0x03, 0x05, 0x05, 0x04, 0x04, 0x00, 0x00, 0x01, 0x7D,
           0x01, 0x02, 0x03, 0x00, 0x04, 0x11, 0x05, 0x12, 0x21, 0x31, 0x41, 0x06,
           0x13, 0x51, 0x61, 0x07, 0x22, 0x71, 0x14, 0x32, 0x81, 0x91, 0xA1, 0x08,
           0x23, 0x42, 0xB1, 0xC1, 0x15, 0x52, 0xD1, 0xF0, 0x24, 0x33, 0x62, 0x72,
           0x82, 0x09, 0x0A, 0x16, 0x17, 0x18, 0x19, 0x1A, 0x25, 0x26, 0x27, 0x28,
           0x29, 0x2A, 0x34, 0x35, 0x36, 0x37, 0x38, 0x39, 0x3A, 0x43, 0x44, 0x45,
           0x46, 0x47, 0x48, 0x49, 0x4A, 0x53, 0x54, 0x55, 0x56, 0x57, 0x58, 0x59,
           0x5A, 0x63, 0x64, 0x65, 0x66, 0x67, 0x68, 0x69, 0x6A, 0x73, 0x74, 0x75,
           0x76, 0x77, 0x78, 0x79, 0x7A, 0x83, 0x84, 0x85, 0x86, 0x87, 0x88, 0x89,
           0x8A, 0x92, 0x93, 0x94, 0x95, 0x96, 0x97, 0x98, 0x99, 0x9A, 0xA2, 0xA3,
           0xA4, 0xA5, 0xA6, 0xA7, 0xA8, 0xA9, 0xAA, 0xB2, 0xB3, 0xB4, 0xB5, 0xB6,
           0xB7, 0xB8, 0xB9, 0xBA, 0xC2, 0xC3, 0xC4, 0xC5, 0xC6, 0xC7, 0xC8, 0xC9,
           0xCA, 0xD2, 0xD3, 0xD4, 0xD5, 0xD6, 0xD7, 0xD8, 0xD9, 0xDA, 0xE1, 0xE2,
           0xE3, 0xE4, 0xE5, 0xE6, 0xE7, 0xE8, 0xE9, 0xEA, 0xF1, 0xF2, 0xF3, 0xF4,
           0xF5, 0xF6, 0xF7, 0xF8, 0xF9, 0xFA, 0xFF, 0xDA, 0x00, 0x08, 0x01, 0x01,
           0x00, 0x00, 0x3F, 0x00, 0xFB, 0xD5, 0xDB, 0x20, 0xA8, 0xF1, 0x70, 0x3F,
           0xFF, 0xD9
       ])
       file_path = temp_dir / "test.jpg"
       file_path.write_bytes(jpeg_bytes)
       return file_path
   ```

2. Add fixture for test file with known timestamp in name:
   ```python
   @pytest.fixture
   def timestamped_file(temp_dir):
       """Create a file with timestamp in filename."""
       file_path = temp_dir / "IMG_20240115_120000.txt"
       file_path.write_text("Test content")
       return file_path
   ```

These fixtures enable testing without real image/video files.
  </action>
  <verify>
grep -n "sample_text_file\|sample_image_file" tests/conftest.py
  </verify>
  <done>
Test fixtures for sample files exist in conftest.py.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create processing unit and integration tests</name>
  <files>tests/test_processing.py</files>
  <action>
Create tests/test_processing.py with comprehensive tests:

```python
"""Tests for Phase 2 processing functionality."""
import pytest
from datetime import datetime, timezone, timedelta
from pathlib import Path

from app.lib.hashing import calculate_sha256, calculate_perceptual_hash
from app.lib.confidence import calculate_confidence, SOURCE_WEIGHTS
from app.models import ConfidenceLevel


class TestSHA256Hashing:
    """Tests for SHA256 hash calculation."""

    def test_sha256_returns_hex_string(self, sample_text_file):
        """SHA256 returns 64-character hex string."""
        result = calculate_sha256(sample_text_file)
        assert len(result) == 64
        assert all(c in '0123456789abcdef' for c in result)

    def test_sha256_consistent(self, sample_text_file):
        """SHA256 returns same hash for same file."""
        hash1 = calculate_sha256(sample_text_file)
        hash2 = calculate_sha256(sample_text_file)
        assert hash1 == hash2

    def test_sha256_accepts_string_path(self, sample_text_file):
        """SHA256 accepts string path."""
        result = calculate_sha256(str(sample_text_file))
        assert len(result) == 64

    def test_sha256_different_content(self, temp_dir):
        """Different content produces different hash."""
        file1 = temp_dir / "file1.txt"
        file2 = temp_dir / "file2.txt"
        file1.write_text("Content A")
        file2.write_text("Content B")

        hash1 = calculate_sha256(file1)
        hash2 = calculate_sha256(file2)
        assert hash1 != hash2


class TestPerceptualHashing:
    """Tests for perceptual hash calculation."""

    def test_perceptual_hash_image(self, sample_image_file):
        """Perceptual hash works on valid image."""
        result = calculate_perceptual_hash(sample_image_file)
        # Should return a hash string (or None if image too small)
        assert result is None or isinstance(result, str)

    def test_perceptual_hash_non_image(self, sample_text_file):
        """Perceptual hash returns None for non-images."""
        result = calculate_perceptual_hash(sample_text_file)
        assert result is None

    def test_perceptual_hash_missing_file(self, temp_dir):
        """Perceptual hash returns None for missing file."""
        result = calculate_perceptual_hash(temp_dir / "nonexistent.jpg")
        assert result is None


class TestConfidenceScoring:
    """Tests for confidence score calculation."""

    def test_high_confidence_exif_agreement(self):
        """HIGH confidence when EXIF source agrees with others."""
        now = datetime.now(timezone.utc)
        candidates = [
            (now, 'EXIF:DateTimeOriginal'),
            (now, 'EXIF:CreateDate'),
        ]
        dt, confidence, _ = calculate_confidence(candidates)
        assert confidence == ConfidenceLevel.HIGH

    def test_medium_confidence_single_reliable(self):
        """MEDIUM confidence for single reliable source."""
        now = datetime.now(timezone.utc)
        candidates = [
            (now, 'EXIF:ModifyDate'),  # Weight 5
        ]
        dt, confidence, _ = calculate_confidence(candidates)
        assert confidence == ConfidenceLevel.MEDIUM

    def test_low_confidence_filename_only(self):
        """LOW confidence for filename-only timestamp."""
        now = datetime.now(timezone.utc)
        candidates = [
            (now, 'filename_date'),  # Weight 2
        ]
        dt, confidence, _ = calculate_confidence(candidates)
        assert confidence == ConfidenceLevel.LOW

    def test_none_confidence_no_candidates(self):
        """NONE confidence when no candidates."""
        dt, confidence, _ = calculate_confidence([])
        assert confidence == ConfidenceLevel.NONE
        assert dt is None

    def test_min_year_filter(self):
        """Timestamps before min_year are filtered."""
        epoch = datetime(1970, 1, 1, tzinfo=timezone.utc)
        candidates = [
            (epoch, 'EXIF:DateTimeOriginal'),
        ]
        dt, confidence, _ = calculate_confidence(candidates, min_year=2000)
        assert confidence == ConfidenceLevel.NONE
        assert dt is None

    def test_earliest_timestamp_selected(self):
        """Earliest valid timestamp is selected."""
        earlier = datetime(2024, 1, 1, 12, 0, 0, tzinfo=timezone.utc)
        later = datetime(2024, 6, 1, 12, 0, 0, tzinfo=timezone.utc)
        candidates = [
            (later, 'EXIF:CreateDate'),
            (earlier, 'EXIF:DateTimeOriginal'),
        ]
        dt, confidence, _ = calculate_confidence(candidates)
        assert dt == earlier

    def test_agreement_within_tolerance(self):
        """Timestamps within 1 second are considered agreeing."""
        base = datetime(2024, 1, 15, 12, 0, 0, tzinfo=timezone.utc)
        close = base + timedelta(milliseconds=500)
        candidates = [
            (base, 'EXIF:DateTimeOriginal'),
            (close, 'filename_datetime'),
        ]
        dt, confidence, _ = calculate_confidence(candidates)
        # Should boost confidence due to agreement
        assert confidence in (ConfidenceLevel.HIGH, ConfidenceLevel.MEDIUM)

    def test_source_weights_defined(self):
        """SOURCE_WEIGHTS contains expected sources."""
        assert 'EXIF:DateTimeOriginal' in SOURCE_WEIGHTS
        assert SOURCE_WEIGHTS['EXIF:DateTimeOriginal'] > SOURCE_WEIGHTS['filename_date']


class TestProcessSingleFile:
    """Tests for the complete processing pipeline."""

    def test_process_returns_dict(self, sample_text_file):
        """process_single_file returns dict with required fields."""
        from app.lib.processing import process_single_file

        result = process_single_file(sample_text_file)

        assert isinstance(result, dict)
        assert 'status' in result
        assert 'sha256' in result
        assert 'confidence' in result

    def test_process_includes_sha256(self, sample_text_file):
        """Processed file has SHA256 hash."""
        from app.lib.processing import process_single_file

        result = process_single_file(sample_text_file)

        assert result['sha256'] is not None
        assert len(result['sha256']) == 64

    def test_process_handles_missing_file(self, temp_dir):
        """Missing file returns error status."""
        from app.lib.processing import process_single_file

        result = process_single_file(temp_dir / "nonexistent.jpg")

        assert result['status'] == 'error'
        assert result['error'] is not None

    def test_process_extracts_filename_timestamp(self, timestamped_file):
        """File with timestamp in name extracts it."""
        from app.lib.processing import process_single_file

        result = process_single_file(timestamped_file)

        # Should find timestamp from filename
        assert result['status'] == 'success'
        # Timestamp candidates should include filename source
        assert result['timestamp_candidates'] is not None
```

Follow existing test patterns:
- Use pytest fixtures
- Group tests by component in classes
- Clear test names describing expected behavior
- Test both success and error cases
  </action>
  <verify>
pytest tests/test_processing.py --collect-only 2>/dev/null || python3 -c "import ast; ast.parse(open('tests/test_processing.py').read()); print('Syntax OK')"
  </verify>
  <done>
tests/test_processing.py exists with unit tests for hashing, confidence scoring, and processing pipeline.
  </done>
</task>

</tasks>

<verification>
1. Test fixtures exist:
   ```bash
   grep -n "def sample_text_file\|def sample_image_file" tests/conftest.py
   ```

2. Test classes cover all components:
   ```bash
   grep -n "class Test" tests/test_processing.py
   ```

3. Tests are syntactically valid:
   ```bash
   python3 -c "import ast; ast.parse(open('tests/test_processing.py').read())"
   ```

4. Run tests (if dependencies installed):
   ```bash
   pytest tests/test_processing.py -v 2>/dev/null || echo "Run after dependencies installed"
   ```
</verification>

<success_criteria>
1. tests/conftest.py has fixtures for sample text file, image file, and timestamped file
2. tests/test_processing.py has test classes for SHA256, perceptual hash, confidence, and processing
3. Tests cover success cases, error cases, and edge cases
4. All test files have valid Python syntax
5. Tests follow existing project test patterns
</success_criteria>

<output>
After completion, create `.planning/phases/02-background-workers-core-processing/02-04-SUMMARY.md`
</output>
